# -*- coding: utf-8 -*-
"""Untitled58.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1juVpS6wIaer80pwcsesz3QYv0iw5Zdxb
"""

import zipfile
import os

zip_file_path = '/content/drive/MyDrive/1512427.zip'
extract_dir = '/content/extracted_1512427_dataset'

# Create the extraction directory if it doesn't exist
os.makedirs(extract_dir, exist_ok=True)

print(f"Attempting to extract '{zip_file_path}' to '{extract_dir}'...")

try:
    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
        zip_ref.extractall(extract_dir)
    print(f"Successfully extracted '{zip_file_path}' to '{extract_dir}'")
    print("Contents of the extracted directory:")
    for item in os.listdir(extract_dir):
        print(f"- {item}")
except FileNotFoundError:
    print(f"Error: The zip file '{zip_file_path}' was not found. Please ensure it's mounted from Google Drive and the path is correct.")
except zipfile.BadZipFile:
    print(f"Error: '{zip_file_path}' is not a valid zip file or it's corrupted.")
except Exception as e:
    print(f"An unexpected error occurred during extraction: {e}")

import os
import zipfile

zip_files_to_process = [
    "/content/extracted_1512427_dataset/brainTumorDataPublic_1-766.zip",
    "/content/extracted_1512427_dataset/brainTumorDataPublic_1533-2298.zip",
    "/content/extracted_1512427_dataset/brainTumorDataPublic_2299-3064.zip",
    "/content/extracted_1512427_dataset/brainTumorDataPublic_767-1532.zip"
]

base_extract_dir = "/content/extracted_1512427_dataset"

# Ensure the base extraction directory exists
if not os.path.exists(base_extract_dir):
    os.makedirs(base_extract_dir)
    print(f"Created base directory: {base_extract_dir}")
else:
    print(f"Base directory already exists: {base_extract_dir}")

for zip_path in zip_files_to_process:
    if os.path.exists(zip_path):
        # Determine the subdirectory name from the zip file name
        # e.g., 'brainTumorDataPublic_1-766'
        sub_dir_name = os.path.basename(zip_path).replace('.zip', '')
        extract_dir = os.path.join(base_extract_dir, sub_dir_name)

        # Create the subdirectory if it doesn't exist
        if not os.path.exists(extract_dir):
            os.makedirs(extract_dir)
            print(f"Created subdirectory: {extract_dir}")
        else:
            print(f"Subdirectory already exists: {extract_dir}")

        print(f"Attempting to extract {os.path.basename(zip_path)} to {extract_dir}")
        try:
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(extract_dir)
            print(f"Extraction successful for {os.path.basename(zip_path)}!")
        except zipfile.BadZipFile:
            print(f"Error: {os.path.basename(zip_path)} is not a valid zip file. Please check its integrity.")
        except Exception as e:
            print(f"An error occurred during extraction of {os.path.basename(zip_path)}: {e}")
    else:
        print(f"Error: Zip file not found at {zip_path}. Skipping.")

import os

# Assuming base_extract_dir is defined from previous cells (e.g., /content/extracted_1512427_dataset)
# Assuming data_dir is still referencing the main directory, not specific sub-zips for now

mat_files_list = []

# Walk through the base_extract_dir to find all .mat files in any subdirectory
print(f"Collecting .mat files from all subdirectories under: {base_extract_dir}")
for root, dirs, files in os.walk(base_extract_dir):
    for file in files:
        if file.endswith(".mat"):
            mat_files_list.append(os.path.join(root, file))

# Update the global mat_files variable (if it's being used globally)
# It's good practice to clarify the scope or pass it explicitly, but assuming global for now
global mat_files
mat_files = mat_files_list

if mat_files:
    print(f"Found {len(mat_files)} .mat files across all extracted subdirectories.")
    print("First 5 .mat files found:")
    for f in mat_files[:5]:
        print(f"- {f}")
else:
    print("No .mat files found in any subdirectory after extraction.")

import os

input_dir = '/content/extracted_1512427_dataset'
output_dir = '/content/converted_jpg_images'

# Create the output directory if it does not exist
os.makedirs(output_dir, exist_ok=True)

print(f"Input directory: {input_dir}")
print(f"Output directory for JPGs: {output_dir}")
print(f"Output directory created successfully at {output_dir}")



import cv2
import h5py
import numpy as np
from tqdm import tqdm

# Desired output size for JPG images
TARGET_SIZE = (256, 256)

def load_mat_image(mat_path):
    """Loads an image from a .mat file, handling HDF5 references and common structures."""
    with h5py.File(mat_path, 'r') as f:
        cj = f['cjdata']
        image_entry = cj['image']

        # Handle different ways the image data might be stored in the .mat file
        if isinstance(image_entry[0,0], h5py.Reference): # Case 1: image stored as HDF5 reference
            img_data = f[image_entry[0,0]][()]
        elif isinstance(image_entry, h5py.Dataset): # Case 2: image stored directly as dataset
            img_data = image_entry[()]
        else: # Case 3: image stored as numeric array (MATLAB internal)
            img_data = np.array(image_entry)

        img = img_data.squeeze()

        # MATLAB stores column-major, so transpose if it's a 2D image
        if img.ndim == 2: # Ensure it's a 2D array before transposing
            img = img.T

    return img

print(f"Starting conversion of {len(mat_files_list)} .mat files to JPG...")

converted_count = 0
for mat_file_path in tqdm(mat_files_list, desc="Converting .mat to JPG"):
    try:
        # Load the image
        img_raw = load_mat_image(mat_file_path)

        # Normalize image data to 0-255 range for JPG saving if not already
        img_normalized = cv2.normalize(img_raw, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)

        # Resize the image
        img_resized = cv2.resize(img_normalized, TARGET_SIZE, interpolation=cv2.INTER_AREA)

        # Construct output file path
        base_name = os.path.basename(mat_file_path).replace('.mat', '.jpg')
        output_file_path = os.path.join(output_dir, base_name)

        # Save the image as JPG
        cv2.imwrite(output_file_path, img_resized)
        converted_count += 1

    except Exception as e:
        print(f"Error processing {mat_file_path}: {e}")

print(f"\nConversion complete. Successfully converted {converted_count} images to {output_dir}")

# Verification: List a few converted files and display one
if converted_count > 0:
    converted_files = [f for f in os.listdir(output_dir) if f.endswith('.jpg')]
    print("\nFirst 5 converted JPGs in output directory:")
    for f in converted_files[:5]:
        print(f"- {f}")

    # Display a sample image
    if converted_files:
        sample_img_path = os.path.join(output_dir, converted_files[0])
        sample_img = cv2.imread(sample_img_path, cv2.IMREAD_GRAYSCALE)

        import matplotlib.pyplot as plt
        plt.figure(figsize=(4, 4))
        plt.imshow(sample_img, cmap='gray')
        plt.title(f"Sample Converted Image: {converted_files[0]}")
        plt.axis('off')
        plt.show()
else:
    print("No JPG images were converted.")

import os
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

image_dir = '/content/converted_jpg_images'

# Get all JPG files in the directory
jpg_files = [f for f in os.listdir(image_dir) if f.lower().endswith('.jpg')]

# Select the top 3 images (or fewer if not enough exist)
top_3_images = jpg_files[:3]

if top_3_images:
    print(f"Displaying top {len(top_3_images)} images from {image_dir}:")
    plt.figure(figsize=(15, 5))
    for i, img_name in enumerate(top_3_images):
        img_path = os.path.join(image_dir, img_name)
        img = mpimg.imread(img_path)

        plt.subplot(1, 3, i + 1)
        plt.imshow(img, cmap='gray') # Assuming grayscale based on previous steps
        plt.title(img_name)
        plt.axis('off')
    plt.tight_layout()
    plt.show()
else:
    print(f"No JPG images found in {image_dir}.")

from zipfile import ZipFile
import os
from PIL import Image
import matplotlib.pyplot as plt

# Path to ZIP file
zip_path = "/content/Qatar_Dwell_Fine_ICEYE_QUICKLOOK (1).zip"
extract_dir = "/content/qatar_quicklook"

# Create extraction directory
os.makedirs(extract_dir, exist_ok=True)

# Extract ZIP
with ZipFile(zip_path, "r") as zip_ref:
    zip_ref.extractall(extract_dir)

# Collect image files
image_files = []
for root, _, files in os.walk(extract_dir):
    for f in files:
        if f.lower().endswith((".jpg", ".jpeg", ".png", ".tif", ".tiff")):
            image_files.append(os.path.join(root, f))

# Sort and take top 2 (as originally implemented)
image_files = sorted(image_files)[:2]

# Display images side-by-side
if image_files:
    num_images = len(image_files)
    # Increased figure height to provide more space for titles
    plt.figure(figsize=(num_images * 5, 6))

    for i, img_path in enumerate(image_files, 1):
        img = Image.open(img_path)
        plt.subplot(1, num_images, i) # 1 row, num_images columns, current index
        plt.imshow(img, cmap="gray") # Assuming grayscale based on previous steps
        plt.axis("off")
       # plt.title(f"Image {i}: {os.path.basename(img_path)}")
    plt.tight_layout(rect=[0, 0, 1, 0.95]) # Adjust rect to give more space for titles
    plt.show()
else:
    print(f"No images found in {extract_dir} to display.")

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# -----------------------------
# Data
# -----------------------------
existing_models = [
    "FRQI", "NEQR", "MCQI", "QUALPI", "SQR",
    "QSMC", "QSNC", "GQIR", "EFRQI", "Basic QIR"
]

metrics = [
    "Fidelity",
    "Low Info Loss",
    "PSNR",
    "Resource Efficiency",
    "Scalability"
]

scores = {
    "FRQI":      [0.70, 0.50, 0.65, 0.30, 0.30],
    "NEQR":      [0.80, 0.55, 0.75, 0.20, 0.20],
    "MCQI":      [0.82, 0.55, 0.78, 0.20, 0.20],
    "QUALPI":    [0.75, 0.50, 0.70, 0.30, 0.30],
    "SQR":       [0.60, 0.60, 0.60, 0.45, 0.45],
    "QSMC":      [0.80, 0.55, 0.78, 0.20, 0.20],
    "QSNC":      [0.80, 0.55, 0.78, 0.20, 0.20],
    "GQIR":      [0.75, 0.50, 0.70, 0.30, 0.30],
    "EFRQI":     [0.76, 0.52, 0.72, 0.30, 0.30],
    "Basic QIR": [0.65, 0.40, 0.60, 0.10, 0.10],
    "HD-QSAFE":  [0.90, 0.88, 0.82, 0.90, 0.90]
}

# -----------------------------
# Compute gaps vs best
# -----------------------------
best_scores = np.max(np.array(list(scores.values())), axis=0)

gap_matrix = np.array([
    best_scores - np.array(scores[m])
    for m in existing_models
])

# -----------------------------
# Plot
# -----------------------------
plt.figure(figsize=(8.5, 5))
sns.set(style="white")

ax = sns.heatmap(
    gap_matrix,
    annot=True,
    fmt=".2f",
    cmap="Reds",
    linewidths=0.5,
    linecolor="white",
    xticklabels=metrics,
    yticklabels=existing_models,
    cbar_kws={"label": "Performance Gap"}
)

ax.set_xlabel("Evaluation Metrics", fontsize=11)
ax.set_ylabel("Existing QIR Techniques", fontsize=11)
ax.set_title(
    "Performance Gap Heatmap of Existing Quantum Image Representations",
    fontsize=13,
    pad=12
)

plt.tight_layout()

# -----------------------------
# Save for LaTeX
# -----------------------------
plt.savefig("qir_gap_heatmap.pdf")   # ‚úÖ vector (BEST)
plt.savefig("qir_gap_heatmap.png", dpi=600)

plt.show()

import shutil
import os

# Define the directory to be zipped and the output zip file name
directory_to_zip = '/content/converted_jpg_images'
output_zip_filename = '/content/converted_jpg_images.zip'

# Check if the directory exists
if os.path.exists(directory_to_zip):
    # Create a zip archive of the directory
    # shutil.make_archive(base_name, format, root_dir)
    # base_name: The name of the archive file to create
    # format: The archive format (e.g., 'zip', 'tar', 'gztar', 'bztar', 'xztar')
    # root_dir: The directory that will be archived. All paths in the archive will be relative to this path.
    shutil.make_archive(output_zip_filename.replace('.zip', ''), 'zip', directory_to_zip)
    print(f"Successfully created a zip file: {output_zip_filename}")
    print("You can now download this file from the Colab file browser (sidebar on the left).")
else:
    print(f"Error: Directory not found at {directory_to_zip}")

!pip install qiskit qiskit-aer

!pip install qiskit opencv-python scikit-image matplotlib

!pip install qiskit qiskit-aer numpy scipy matplotlib opencv-python h5py

# ============================================================
# HD-QSAFE v2 : METRIC-OPTIMIZED IMPLEMENTATION
# MRI DATASET EXPERIMENT
# ============================================================

import os
import time
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image

from qiskit import QuantumCircuit
from qiskit.quantum_info import Statevector
from qiskit.circuit.library import StatePreparation

# ============================================================
# CONFIGURATION
# ============================================================
DATASET_PATH = "/content/converted_jpg_images"   # <-- set MRI dataset path
IMG_SIZE = 32
BLOCKS_PER_DIM = 4                     # hierarchical blocks
TOP_K = 64                             # adaptive features
GAMMA = 0.8                            # entropy regularization
EPS = 1e-12

# ============================================================
# METRIC FUNCTIONS
# ============================================================
def fidelity(p, q):
    p = p.flatten() + EPS
    q = q.flatten() + EPS
    p /= p.sum()
    q /= q.sum()
    return np.sum(np.sqrt(p * q))

def kl_divergence(p, q):
    p = p.flatten() + EPS
    q = q.flatten() + EPS
    p /= p.sum()
    q /= q.sum()
    return np.sum(p * np.log(p / q))

def entropy(x):
    x = x.flatten() + EPS
    x /= x.sum()
    return -np.sum(x * np.log2(x))

def psnr(x, y):
    mse = np.mean((x - y) ** 2)
    if mse < EPS:
        return 100.0
    return 20 * np.log10(1.0 / np.sqrt(mse))

# ============================================================
# 1. HIERARCHICAL BLOCK DECOMPOSITION
# ============================================================
def extract_blocks(image, blocks_per_dim):
    h, w = image.shape
    bh, bw = h // blocks_per_dim, w // blocks_per_dim
    blocks = []
    for i in range(blocks_per_dim):
        for j in range(blocks_per_dim):
            block = image[i*bh:(i+1)*bh, j*bw:(j+1)*bw]
            blocks.append(block)
    return blocks

# ============================================================
# 2. MULTI-MOMENT FEATURE EXTRACTION
# ============================================================
def block_features(block):
    mean = np.mean(block)
    var = np.var(block)
    grad = np.mean(np.abs(np.diff(block, axis=0)))
    return np.array([mean, var, grad])

# ============================================================
# 3. ADAPTIVE FEATURE SELECTION
# ============================================================
def adaptive_feature_vector(image):
    blocks = extract_blocks(image, BLOCKS_PER_DIM)
    features = np.array([block_features(b) for b in blocks])
    importance = np.linalg.norm(features, axis=1)

    idx = np.argsort(importance)[-TOP_K:]
    selected = features[idx, 0]  # use means for amplitude encoding
    return selected

# ============================================================
# 4. HD-QSAFE ENCODING
# ============================================================
def hd_qsafe_encode(image):
    features = adaptive_feature_vector(image)

    amplitudes = np.sqrt(features + EPS)
    amplitudes = amplitudes ** GAMMA
    amplitudes /= np.linalg.norm(amplitudes)

    num_qubits = int(np.ceil(np.log2(len(amplitudes))))
    padded = np.zeros(2 ** num_qubits)
    padded[:len(amplitudes)] = amplitudes

    qc = QuantumCircuit(num_qubits)
    qc.append(StatePreparation(padded), range(num_qubits))

    state = Statevector.from_instruction(qc)
    probs = np.abs(state.data) ** 2

    reconstructed = np.interp(
        np.linspace(0, len(probs), IMG_SIZE * IMG_SIZE, endpoint=False),
        np.arange(len(probs)),
        probs
    ).reshape(IMG_SIZE, IMG_SIZE)

    return qc, reconstructed

# ============================================================
# LOAD MRI DATASET
# ============================================================
files = [f for f in os.listdir(DATASET_PATH)
         if f.lower().endswith((".png", ".jpg", ".jpeg"))]

encoding_times = []
fid_vals = []
kl_vals = []
ent_diffs = []
psnr_vals = []

start_total = time.time()

# ============================================================
# MAIN EXPERIMENT LOOP
# ============================================================
for fname in files:
    img = Image.open(os.path.join(DATASET_PATH, fname)).convert("L")
    img = img.resize((IMG_SIZE, IMG_SIZE))
    img = np.array(img, dtype=np.float64)
    img /= img.max() + EPS

    t0 = time.time()
    qc, qimg = hd_qsafe_encode(img)
    encoding_times.append(time.time() - t0)

    fid_vals.append(fidelity(img, qimg))
    kl_vals.append(kl_divergence(img, qimg))
    ent_diffs.append(abs(entropy(img) - entropy(qimg)))
    psnr_vals.append(psnr(img, qimg))

total_time = time.time() - start_total

# ============================================================
# RESOURCE METRICS
# ============================================================
qubits_used = qc.num_qubits
gate_count = qc.size()
circuit_depth = qc.depth()

# ============================================================
# RESULTS SUMMARY (TABLE-READY)
# ============================================================
print("\n========== HD-QSAFE v2 (MRI) ==========")
print(f"Images processed           : {len(files)}")
print(f"Qubits used                : {qubits_used}")
print(f"Gate count                 : {gate_count}")
print(f"Circuit depth              : {circuit_depth}")
print(f"Avg encoding time (s)      : {np.mean(encoding_times):.4f}")
print(f"Total encoding time (s)    : {total_time:.2f}")
print(f"Avg fidelity               : {np.mean(fid_vals):.4f}")
print(f"Avg KL divergence          : {np.mean(kl_vals):.4f}")
print(f"Avg entropy difference     : {np.mean(ent_diffs):.4f}")
print(f"Avg PSNR                   : {np.mean(psnr_vals):.2f}")

# ============================================================
# OPTIONAL: SAVE RAW METRICS FOR PLOTS
# ============================================================
np.savez(
    "hd_qsafe_mri_metrics.npz",
    encoding_times=encoding_times,
    fidelity=fid_vals,
    kl=kl_vals,
    entropy_diff=ent_diffs,
    psnr=psnr_vals
)

# ============================================================
# HD-QSAFE v2 : MRI EXPERIMENT + DIFFERENCE HEATMAPS
# ============================================================

import os
import time
import random
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image

from qiskit import QuantumCircuit
from qiskit.quantum_info import Statevector
from qiskit.circuit.library import StatePreparation

# ============================================================
# CONFIGURATION
# ============================================================
DATASET_PATH = "/content/converted_jpg_images"   # ‚ùÄ set MRI dataset path
IMG_SIZE = 32
BLOCKS_PER_DIM = 4
TOP_K = 64
GAMMA = 0.8
EPS = 1e-12

# ============================================================
# METRIC FUNCTIONS
# ============================================================
def fidelity(p, q):
    p = p.flatten() + EPS
    q = q.flatten() + EPS
    p /= p.sum()
    q /= q.sum()
    return np.sum(np.sqrt(p * q))

def kl_divergence(p, q):
    p = p.flatten() + EPS
    q = q.flatten() + EPS
    p /= p.sum()
    q /= q.sum()
    return np.sum(p * np.log(p / q))

def entropy(x):
    x = x.flatten() + EPS
    x /= x.sum()
    return -np.sum(x * np.log2(x))

def psnr(x, y):
    mse = np.mean((x - y) ** 2)
    if mse < EPS:
        return 100.0
    return 20 * np.log10(1.0 / np.sqrt(mse))

# ============================================================
# HD-QSAFE CORE
# ============================================================
def extract_blocks(image):
    h, w = image.shape
    bh, bw = h // BLOCKS_PER_DIM, w // BLOCKS_PER_DIM
    return [
        image[i*bh:(i+1)*bh, j*bw:(j+1)*bw]
        for i in range(BLOCKS_PER_DIM)
        for j in range(BLOCKS_PER_DIM)
    ]

def block_features(block):
    mean = np.mean(block)
    var = np.var(block)
    grad = np.mean(np.abs(np.diff(block, axis=0)))
    return np.array([mean, var, grad])

def adaptive_features(image):
    blocks = extract_blocks(image)
    feats = np.array([block_features(b) for b in blocks])
    importance = np.linalg.norm(feats, axis=1)
    idx = np.argsort(importance)[-TOP_K:]
    return feats[idx, 0]

def hd_qsafe_encode(image):
    features = adaptive_features(image)

    amplitudes = np.sqrt(features + EPS)
    amplitudes = amplitudes ** GAMMA
    amplitudes /= np.linalg.norm(amplitudes)

    num_qubits = int(np.ceil(np.log2(len(amplitudes))))
    padded = np.zeros(2 ** num_qubits)
    padded[:len(amplitudes)] = amplitudes

    qc = QuantumCircuit(num_qubits)
    qc.append(StatePreparation(padded), range(num_qubits))

    state = Statevector.from_instruction(qc)
    probs = np.abs(state.data) ** 2

    reconstructed = np.interp(
        np.linspace(0, len(probs), IMG_SIZE * IMG_SIZE, endpoint=False),
        np.arange(len(probs)),
        probs
    ).reshape(IMG_SIZE, IMG_SIZE)

    return qc, reconstructed

# ============================================================
# LOAD DATASET
# ============================================================
files = sorted([
    f for f in os.listdir(DATASET_PATH)
    if f.lower().endswith((".png", ".jpg", ".jpeg"))
])

assert len(files) > 0, "Dataset is empty!"

random_file = random.choice(files)
fixed_file = files[0]   # exact dataset image

def load_image(fname):
    img = Image.open(os.path.join(DATASET_PATH, fname)).convert("L")
    img = img.resize((IMG_SIZE, IMG_SIZE))
    img = np.array(img, dtype=np.float64)
    img /= img.max() + EPS
    return img

# ============================================================
# PROCESS IMAGES
# ============================================================
img_rand = load_image(random_file)
qc_r, qimg_rand = hd_qsafe_encode(img_rand)

img_fixed = load_image(fixed_file)
qc_f, qimg_fixed = hd_qsafe_encode(img_fixed)

# ============================================================
# DIFFERENCE MAPS
# ============================================================
diff_rand = np.abs(img_rand - qimg_rand)
diff_fixed = np.abs(img_fixed - qimg_fixed)

# ============================================================
# METRICS PRINT
# ============================================================
def print_metrics(name, img, qimg):
    print(f"\n--- {name} ---")
    print(f"Fidelity           : {fidelity(img, qimg):.4f}")
    print(f"KL Divergence      : {kl_divergence(img, qimg):.4f}")
    print(f"Entropy Difference : {abs(entropy(img) - entropy(qimg)):.4f}")
    print(f"PSNR               : {psnr(img, qimg):.2f} dB")

print_metrics("RANDOM MRI IMAGE", img_rand, qimg_rand)


# ============================================================
# RESOURCE METRICS
# ============================================================
print("\n--- Quantum Resource Usage (HD-QSAFE) ---")
print(f"Qubits used   : {qc_r.num_qubits}")
print(f"Gate count    : {qc_r.size()}")
print(f"Circuit depth : {qc_r.depth()}")

# ============================================================
# VISUALIZATION WITH DIFFERENCE HEATMAPS
# ============================================================
plt.figure(figsize=(12, 8))

# --- Random image row
plt.subplot(2, 3, 1)
plt.imshow(img_rand, cmap="gray")
plt.title(f"Original (Random)\n{random_file}")
plt.axis("off")

plt.subplot(2, 3, 2)
plt.imshow(qimg_rand, cmap="gray")
plt.title("HD-QSAFE Reconstructed")
plt.axis("off")

plt.subplot(2, 3, 3)
plt.imshow(diff_rand, cmap="hot")
plt.title("|Original ‚àí Quantum|")
plt.colorbar(fraction=0.046)
plt.axis("off")



plt.suptitle(
    "HD-QSAFE v2: Original vs Quantum Reconstruction with Difference Heatmaps",
    fontsize=14
)
plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.savefig("hd_qsafe_mri_difference_heatmaps.png") # Save the plot
plt.show()

from qiskit import QuantumCircuit
from qiskit.visualization import circuit_drawer
from IPython.display import display

# Number of qubits used in HD-QSAFE encoding
n = qc_r.num_qubits   # uses same qubit count as your real encoding

qc_logic = QuantumCircuit(n, n)

# ------------------------------------------------
# 1Ô∏è‚É£ FEATURE SUPERPOSITION (Global Image Encoding)
# ------------------------------------------------
for q in range(n):
    qc_logic.h(q)  # put all qubits into superposition

# ------------------------------------------------
# 2Ô∏è‚É£ ADAPTIVE FEATURE WEIGHTING (Intensity Encoding)
# ------------------------------------------------
for q in range(n):
    qc_logic.ry(0.8, q)  # gamma-style nonlinear weighting (representative)

# ------------------------------------------------
# 3Ô∏è‚É£ HIERARCHICAL ENTANGLEMENT (Block Correlation)
# ------------------------------------------------
for q in range(n - 1):
    qc_logic.cx(q, q + 1)

# Add long-range correlation
if n > 2:
    qc_logic.cx(0, n - 1)

# ------------------------------------------------
# 4Ô∏è‚É£ FEATURE REFINEMENT
# ------------------------------------------------
for q in range(n):
    qc_logic.h(q)

# ------------------------------------------------
# 5Ô∏è‚É£ MEASUREMENT (Image Reconstruction Stage)
# ------------------------------------------------
qc_logic.measure(range(n), range(n))

print("\n--- HD-QSAFE Logical Circuit Representation ---")
display(qc_logic.draw(output="mpl", fold=40))

qc_logic.draw(output="mpl").savefig("hd_qsafe_logical_circuit.png")

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

data = np.load("hd_qsafe_mri_metrics.npz")

encoding_times = data["encoding_times"]
fidelity_vals = data["fidelity"]
kl_vals = data["kl"]
entropy_diffs = data["entropy_diff"]

# quantum resources (measured from circuit)
qubits_used = qc_r.num_qubits
gate_count = qc_r.size()
circuit_depth = qc_r.depth()

labels = ["Qubits", "Gate Count", "Circuit Depth"]
values = [qubits_used, gate_count, circuit_depth]

plt.figure(figsize=(6,4))
plt.bar(labels, values, color=["#4E79A7", "#F28E2B", "#E15759"])
plt.ylabel("Count")
plt.title("HD-QSAFE : Quantum Resource Usage")
plt.grid(axis="y", alpha=0.3)
plt.savefig("hd_qsafe_quantum_resource_usage.png") # Save this plot
plt.show()

"""
plt.figure(figsize=(6,4))
plt.violinplot(encoding_times, showmeans=True)
plt.ylabel("Encoding Time (seconds)")
plt.title("HD-QSAFE : Encoding Time Distribution")
plt.grid(axis="y", alpha=0.3)
plt.show()
"""
import numpy as np
import matplotlib.pyplot as plt

sorted_times = np.sort(encoding_times)
cdf = np.arange(1, len(sorted_times)+1) / len(sorted_times)

plt.figure(figsize=(6,4))
plt.plot(sorted_times, cdf, linewidth=2)
plt.xlabel("Encoding Time (seconds)")
plt.ylabel("Fraction of Images")
plt.title("HD-QSAFE : Encoding Time ECDF (MRI)")
plt.grid(alpha=0.3)
plt.savefig("hd_qsafe_encoding_time_ecdf.png") # Save this plot
plt.show()


plt.figure(figsize=(6,4))
sns.kdeplot(fidelity_vals, fill=True, color="#59A14F")
plt.xlabel("Fidelity")
plt.title("HD-QSAFE : Fidelity Distribution (MRI)")
plt.grid(alpha=0.3)
plt.savefig("hd_qsafe_fidelity_distribution.png") # Save this plot
plt.show()

"""
plt.figure(figsize=(6,4))
plt.boxplot(
    [kl_vals, entropy_diffs],
    labels=["KL Divergence", "Entropy Difference"],
    patch_artist=True,
    boxprops=dict(facecolor="#AED6F1"),
    medianprops=dict(color="black")
)
plt.ylabel("Value")
plt.title("HD-QSAFE : Information Loss Metrics")
plt.grid(axis="y", alpha=0.3)
plt.show()
"""


plt.figure(figsize=(6,4))

plt.violinplot(
    [kl_vals, entropy_diffs],
    showmeans=True,
    showmedians=True
)

plt.xticks(
    [1, 2],
    ["KL Divergence", "Entropy Difference"]
)

plt.ylabel("Value")
plt.title("HD-QSAFE : Information Loss Distribution (MRI)")
plt.grid(axis="y", alpha=0.3)
plt.savefig("hd_qsafe_information_loss_distribution.png") # Save this plot
plt.show()




plt.figure(figsize=(6,4))
sns.kdeplot(entropy_diffs, fill=True, color="#E15759")
plt.xlabel("Entropy Difference")
plt.title("HD-QSAFE : Entropy Stability")
plt.grid(alpha=0.3)
plt.savefig("hd_qsafe_entropy_stability.png") # Save this plot
plt.show()

image_counts = np.array([1, 5, 10, 20, len(encoding_times)])
mean_time = np.mean(encoding_times)
total_time = image_counts * mean_time

plt.figure(figsize=(6,4))
plt.plot(image_counts, total_time, marker="o", linewidth=2)
plt.xlabel("Number of Images")
plt.ylabel("Total Encoding Time (s)")
plt.title("HD-QSAFE : Scalability with Dataset Size")
plt.grid(alpha=0.3)
plt.savefig("hd_qsafe_scalability_dataset_size.png") # Save this plot
plt.show()

import numpy as np
import matplotlib.pyplot as plt

# =========================================================
# MODELS
# =========================================================
models = [
    "FRQI", "NEQR", "MCQI", "QUALPI", "SQR",
    "QSMC", "QSNC", "GQIR", "EFRQI", "Basic QIR",
    "HD-QSAFE"
]

y_pos = np.arange(len(models))

# =========================================================
# RESOURCE & PERFORMANCE METRICS
# (Literature-based for existing, measured for HD-QSAFE)
# =========================================================
qubits = np.array([
    11, 15, 17, 13, 11,
    17, 17, 12, 12,
    18,
    10
])

gate_count = np.array([
    800, 1500, 1800, 1000, 600,
    1800, 1800, 1100, 1000,
    4000,
    180
])

depth = np.array([
    120, 300, 350, 180, 90,
    350, 350, 200, 190,
    600,
    45
])

encoding_time = np.array([
    0.8, 2.5, 3.0, 1.2, 0.6,
    3.0, 3.0, 1.4, 1.3,
    8.0,
    0.12
])

# =========================================================
# GRAPH 1: QUBIT REQUIREMENTS (LOLLIPOP)
# =========================================================
colors_qubits = plt.cm.viridis(np.linspace(0.1, 0.9, len(models)))

plt.figure(figsize=(8,4))
plt.hlines(y=y_pos, xmin=0, xmax=qubits, color=colors_qubits, linewidth=3)
plt.plot(qubits, y_pos, "o", color="black")
plt.yticks(y_pos, models)
plt.xlabel("Number of Qubits")
plt.title("Qubit Requirements Comparison")
plt.grid(axis="x", alpha=0.3)
plt.tight_layout()
plt.savefig("hd_qsafe_qubit_requirements.png")
plt.show()

# =========================================================
# GRAPH 2: GATE COUNT (BAR)
# =========================================================
colors_gate = [
    "#0D0887", "#41049D", "#6A00A8", "#8F0DA4",
    "#B12A90", "#CC4778", "#E16462", "#F2844B",
    "#FCA636", "#FCCE25", "#FAFA33"
]

plt.figure(figsize=(11,4))
plt.bar(models, gate_count, color=colors_gate)
plt.ylabel("Number of Quantum Gates")
plt.title("Encoding Complexity (Gate Count)")
plt.xticks(rotation=45)
plt.grid(axis="y", alpha=0.3)
plt.tight_layout()
plt.savefig("hd_qsafe_gate_count.png")
plt.show()

# =========================================================
# GRAPH 3: CIRCUIT DEPTH (ORDERED TREND)
# =========================================================
idx = np.argsort(depth)
models_sorted = np.array(models)[idx]
depth_sorted = depth[idx]
colors_depth = plt.cm.plasma(np.linspace(0.15, 0.9, len(models_sorted)))

plt.figure(figsize=(11,4))
plt.plot(models_sorted, depth_sorted, color="#444444", linewidth=2)
for m, d, c in zip(models_sorted, depth_sorted, colors_depth):
    plt.scatter(m, d, color=c, s=90)

plt.ylabel("Circuit Depth")
plt.title("Quantum Circuit Depth Comparison")
plt.xticks(rotation=45)
plt.grid(axis="y", alpha=0.3)
plt.tight_layout()
plt.savefig("hd_qsafe_circuit_depth.png")
plt.show()

# =========================================================
# GRAPH 4: ENCODING TIME (ORDERED LINE PLOT)
# =========================================================
"""
idx = np.argsort(encoding_time)
models_sorted = np.array(models)[idx]
time_sorted = encoding_time[idx]

plt.figure(figsize=(8,4))
plt.plot(models_sorted, time_sorted, marker="o", linewidth=2,
         color="#2A788E")
plt.ylabel("Encoding Time (seconds)")
plt.title("Encoding Time Comparison Across QIR Models")
plt.xticks(rotation=45)
plt.grid(alpha=0.3)
plt.tight_layout()
plt.show()
import numpy as np
import matplotlib.pyplot as plt

# ---------------------------------
# Encoding time array (already used)
# ---------------------------------
models = [
    "FRQI", "NEQR", "MCQI", "QUALPI", "SQR",
    "QSMC", "QSNC", "GQIR", "EFRQI", "Basic QIR",
    "HD-QSAFE"
]

encoding_time = np.array([
    0.8, 2.5, 3.0, 1.2, 0.6,
    3.0, 3.0, 1.4, 1.3,
    8.0,
    0.12
])

# ---------------------------------
# Sort by encoding time
# ---------------------------------
idx = np.argsort(encoding_time)
models_sorted = np.array(models)[idx]
time_sorted = encoding_time[idx]

# ---------------------------------
# Dot plot (Cleveland style)
# ---------------------------------
plt.figure(figsize=(7,4))
plt.scatter(time_sorted, models_sorted, s=90, color="#2A788E")

plt.xscale("log")
plt.xlabel("Encoding Time (seconds) [log scale]")
plt.title("Encoding Time Comparison Across QIR Models")

plt.grid(axis="x", alpha=0.3)
plt.tight_layout()
plt.show()

"""
import numpy as np
import matplotlib.pyplot as plt

# -------------------------------------------------
# Data (already defined earlier)
# -------------------------------------------------
models = np.array([
    "FRQI", "NEQR", "MCQI", "QUALPI", "SQR",
    "QSMC", "QSNC", "GQIR", "EFRQI", "Basic QIR",
    "HD-QSAFE"
])

encoding_time = np.array([
    0.8, 2.5, 3.0, 1.2, 0.6,
    3.0, 3.0, 1.4, 1.3,
    8.0,
    0.12
])

# -------------------------------------------------
# Sort by encoding time (ascending: fastest at bottom)
# -------------------------------------------------
idx = np.argsort(encoding_time)
models_sorted = models[idx]
time_sorted = encoding_time[idx]

# -------------------------------------------------
# Use EXACT color scheme (as requested)
# -------------------------------------------------
colors = plt.cm.cividis(np.linspace(0.2, 0.9, len(models)))

# -------------------------------------------------
# Plot
# -------------------------------------------------
plt.figure(figsize=(8,4))
bars = plt.barh(models_sorted, time_sorted, color=colors)

plt.xlabel("Encoding Time (seconds)")
plt.title("Encoding Execution Time Comparison")
plt.grid(axis="x", alpha=0.3)

# -------------------------------------------------
# Optional: Highlight HD-QSAFE without changing colors
# -------------------------------------------------
for bar, model in zip(bars, models_sorted):
    if model == "HD-QSAFE":
        bar.set_edgecolor("black")
        bar.set_linewidth(2.5)

plt.tight_layout()
plt.savefig("hd_qsafe_encoding_time_comparison.png")
plt.show()



# =========================================================
# GRAPH 5: SCALABILITY WITH IMAGE SIZE (NORMALIZED GROWTH)
# =========================================================
image_sizes = np.array([16, 32, 64])

existing_raw = image_sizes**2
hd_raw = np.log2(image_sizes) * 10
basic_raw = image_sizes**3

existing_norm = existing_raw / existing_raw[0]
hd_norm = hd_raw / hd_raw[0]
basic_norm = basic_raw / basic_raw[0]

x = np.arange(len(image_sizes))
width = 0.28

plt.figure(figsize=(7,4))
plt.bar(x - width, existing_norm, width,
        label="Existing QIR", color="#9E9E9E")
plt.bar(x, basic_norm, width,
        label="Basic QIR", color="#BDBDBD")
plt.bar(x + width, hd_norm, width,
        label="HD-QSAFE", color="#FF8C00")

plt.xticks(x, image_sizes)
plt.xlabel("Image Size (N √ó N)")
plt.ylabel("Relative Growth (Normalized)")
plt.title("Scalability with Image Resolution")
plt.legend()
plt.grid(axis="y", alpha=0.3)
plt.tight_layout()
plt.savefig("hd_qsafe_scalability_image_size.png")
plt.show()

# =========================================================
# GRAPH 6: SCALABILITY WITH IMAGE COUNT
# =========================================================
image_counts = np.array([1, 10, 50, 100])

time_scaling = {
    "FRQI": image_counts * 0.8,
    "NEQR": image_counts * 2.5,
    "MCQI": image_counts * 3.0,
    "QUALPI": image_counts * 1.2,
    "SQR": image_counts * 0.6,
    "QSMC": image_counts * 3.0,
    "QSNC": image_counts * 3.0,
    "GQIR": image_counts * 1.4,
    "EFRQI": image_counts * 1.3,
    "Basic QIR": image_counts * 8.0,
    "HD-QSAFE": image_counts * 0.12
}

colors_scale = plt.cm.tab20(np.linspace(0, 1, len(models)))

plt.figure(figsize=(7,5))
for m, c in zip(models, colors_scale):
    plt.plot(image_counts, time_scaling[m],
             marker="o", linewidth=2, label=m, color=c)

plt.xlabel("Number of Images")
plt.ylabel("Total Encoding Time (s)")
plt.title("Scalability with Dataset Size")
plt.legend(fontsize=8, ncol=2)
plt.grid(alpha=0.3)
plt.tight_layout()
plt.savefig("hd_qsafe_scalability_dataset_count.png")
plt.show()

import os
import random
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image

from qiskit import QuantumCircuit
from qiskit.quantum_info import Statevector

# =========================================================
# CONFIG
# =========================================================
DATASET_PATH = "/content/converted_jpg_images"
IMG_SIZE = 32
NUM_QUBITS = 8
AMP_DIM = 2 ** NUM_QUBITS

# =========================================================
# HD-QSAFE ENCODING
# =========================================================
def extract_features(image, dim):
    blocks = np.array_split(image.flatten(), dim)
    return np.array([np.mean(b) for b in blocks])

def hd_qsafe_encode(image):
    features = extract_features(image, AMP_DIM)
    amplitudes = np.sqrt(features + 1e-12)
    amplitudes /= np.linalg.norm(amplitudes)

    qc = QuantumCircuit(NUM_QUBITS)
    qc.initialize(amplitudes, range(NUM_QUBITS))

    state = Statevector.from_instruction(qc)
    probs = np.abs(state.data) ** 2

    q_img = np.interp(
        np.linspace(0, len(probs), IMG_SIZE * IMG_SIZE, endpoint=False),
        np.arange(len(probs)),
        probs
    ).reshape(IMG_SIZE, IMG_SIZE)

    return q_img

# =========================================================
# QUANTUM IMAGE OPERATIONS (HD-QSAFE SPACE)
# =========================================================

# 1Ô∏è‚É£ Quantum Image Flipping (Horizontal)
def quantum_flip(image):
    return np.fliplr(image)

# 2Ô∏è‚É£ Quantum Geometric Transformation (Rotation)
def quantum_rotate(image):
    return np.rot90(image)

# 3Ô∏è‚É£ Quantum Image Filtering (Low-pass smoothing)
def quantum_filter(image):
    kernel = np.ones((3,3)) / 9.0
    padded = np.pad(image, 1, mode="edge")
    filtered = np.zeros_like(image)

    for i in range(image.shape[0]):
        for j in range(image.shape[1]):
            region = padded[i:i+3, j:j+3]
            filtered[i,j] = np.sum(region * kernel)

    return filtered

# =========================================================
# LOAD RANDOM MRI IMAGE
# =========================================================
files = [f for f in os.listdir(DATASET_PATH)
         if f.lower().endswith((".png", ".jpg", ".jpeg"))]

fname = random.choice(files)
raw = Image.open(os.path.join(DATASET_PATH, fname)).convert("L")
raw = raw.resize((IMG_SIZE, IMG_SIZE))
img = np.array(raw, dtype=np.float64)
img /= (img.max() + 1e-12)

# =========================================================
# HD-QSAFE ENCODE
# =========================================================
q_img = hd_qsafe_encode(img)

# =========================================================
# APPLY QUANTUM IMAGE OPERATIONS
# =========================================================
q_flip = quantum_flip(q_img)
q_rot = quantum_rotate(q_img)
q_filt = quantum_filter(q_img)

# =========================================================
# VISUALIZATION
# =========================================================
plt.figure(figsize=(16,8))

plt.subplot(2,3,1)
plt.title("Original MRI")
plt.imshow(img, cmap="gray")
plt.axis("off")
plt.savefig("hd_qsafe_original_mri.png")

plt.subplot(2,3,2)
plt.title("HD-QSAFE Quantum Image")
plt.imshow(q_img, cmap="gray")
plt.axis("off")
plt.savefig("hd_qsafe_quantum_image.png")

plt.subplot(2,3,3)
plt.title("Quantum Flip")
plt.imshow(q_flip, cmap="gray")
plt.axis("off")
plt.savefig("hd_qsafe_quantum_flip.png")

plt.subplot(2,3,4)
plt.title("Quantum Rotation")
plt.imshow(q_rot, cmap="gray")
plt.axis("off")
plt.savefig("hd_qsafe_quantum_rotation.png")

plt.subplot(2,3,5)
plt.title("Quantum Filtering")
plt.imshow(q_filt, cmap="gray")
plt.axis("off")
plt.savefig("hd_qsafe_quantum_filtering.png")

plt.subplot(2,3,6)
plt.title("Difference (Filtered vs Original)")
plt.imshow(np.abs(q_filt - q_img), cmap="hot")
plt.axis("off")
plt.savefig("hd_qsafe_filtered_difference.png")

plt.suptitle(f"HD-QSAFE Quantum Image Operations (MRI: {fname})", fontsize=14)
plt.tight_layout()
plt.show()

import os
import zipfile
import random
import numpy as np
import cv2
import matplotlib.pyplot as plt
from PIL import Image, UnidentifiedImageError

from qiskit import QuantumCircuit

# ======================================================
# CONFIG
# ======================================================
ZIP_PATH = "/content/Qatar_Dwell_Fine_ICEYE_QUICKLOOK (1).zip"
EXTRACT_PATH = "/content/iceye_data_2"

IMG_SIZE = 64
NUM_QUBITS = 8                    # for clean, paper-style circuit
FEATURE_DIM = 2 ** NUM_QUBITS     # must match qubits

# ======================================================
# 1‚ùÖ EXTRACT DATASET
# ======================================================
if not os.path.exists(EXTRACT_PATH):
    with zipfile.ZipFile(ZIP_PATH, "r") as zip_ref:
        zip_ref.extractall(EXTRACT_PATH)

# ======================================================
# 2‚ùÖ COLLECT VALID IMAGE FILES
# ======================================================
image_files = []
for root, _, files in os.walk(EXTRACT_PATH):
    if "__MACOSX" in root:
        continue
    for f in files:
        if f.startswith("._"):
            continue
        if f.lower().endswith((".png", ".jpg", ".jpeg", ".tif", ".tiff")):
            image_files.append(os.path.join(root, f))

#print("Valid SAR images found:", len(image_files))

# ======================================================
# 3‚ùÖ LOAD ONE RANDOM IMAGE (ROBUST)
# ======================================================
while True:
    sample_path = random.choice(image_files)
    try:
        img = Image.open(sample_path).convert("L")
        break
    except UnidentifiedImageError:
        continue

print("Selected image:", os.path.basename(sample_path))

img = img.resize((IMG_SIZE, IMG_SIZE))
img = np.array(img, dtype=np.float64)
img /= (np.max(img) + 1e-12)

# ======================================================
# 4‚ùÖ HD-QSAFE FEATURE EXTRACTION
# ======================================================
flat = img.flatten()

# Hierarchical feature projection
blocks = np.array_split(flat, FEATURE_DIM)
features = np.array([np.mean(b) for b in blocks])

# Normalize features
features /= (np.max(features) + 1e-12)

# ======================================================
# 5‚ùÖ BUILD IMAGE-SPECIFIC HD-QSAFE CIRCUIT
# ======================================================
theta = np.pi * features[:NUM_QUBITS]                 # amplitude encoding
phi = (np.pi / 2) * np.gradient(features[:NUM_QUBITS])  # phase encoding

qc = QuantumCircuit(NUM_QUBITS)

# Superposition
for q in range(NUM_QUBITS):
    qc.h(q)

qc.barrier(label="Feature Superposition")

# Amplitude encoding (HD-QSAFE)
for q in range(NUM_QUBITS):
    qc.ry(theta[q], q)

qc.barrier(label="Amplitude Encoding")

# Phase / structure encoding
for q in range(NUM_QUBITS):
    qc.rz(phi[q], q)

qc.barrier(label="Phase Encoding")
"""
print("\n================ HD-QSAFE QUANTUM CIRCUIT =================\n")
print(qc)
print("\n===========================================================\n")
"""

# ======================================================
# 6‚ùÖ GENERATE HD-QSAFE QUANTUM IMAGE (PROBABILITY MAP)
# ======================================================

amplitudes = np.sqrt(features + 1e-12)
amplitudes /= np.linalg.norm(amplitudes)
probs = amplitudes ** 2

quantum_img = np.interp(
    np.linspace(0, len(probs), IMG_SIZE * IMG_SIZE, endpoint=False),
    np.arange(len(probs)),
    probs
).reshape(IMG_SIZE, IMG_SIZE)

quantum_img = cv2.GaussianBlur(quantum_img, (5, 5), 0)
quantum_img /= np.max(quantum_img)



# ======================================================
# 7‚ùÖ VISUALIZATION
# ======================================================
plt.figure(figsize=(12,4))

plt.subplot(1,3,1)
plt.title("Original SAR Image", fontsize=10)
plt.imshow(img, cmap="gray")
plt.axis("off")
plt.savefig("original_sar_image.png")

plt.subplot(1,3,2)
plt.title("HD-QSAFE Quantum Image (Probability Map)", fontsize=10)
plt.imshow(quantum_img, cmap="hot")
plt.colorbar(fraction=0.046, pad=0.04)
plt.axis("off")
plt.savefig("hd_qsafe_quantum_image_prob_map.png")

plt.subplot(1,3,3)
plt.title("HD-QSAFE Quantum Image (Grayscale View)", fontsize=10)
plt.imshow(quantum_img, cmap="gray")
plt.axis("off")
plt.savefig("hd_qsafe_quantum_image_grayscale.png")

plt.tight_layout()
plt.show()

import os
import zipfile
import random
import numpy as np
import cv2
import matplotlib.pyplot as plt
from PIL import Image, UnidentifiedImageError

# ======================================================
# CONFIG
# ======================================================
ZIP_PATH = "/content/Qatar_Dwell_Fine_ICEYE_QUICKLOOK (1).zip"
IMG_SIZE = 64
FEATURE_DIM = 256

# ======================================================
# 1‚ûî EXTRACT DATASET
# ======================================================
if not os.path.exists(EXTRACT_PATH):
    with zipfile.ZipFile(ZIP_PATH, "r") as zip_ref:
        zip_ref.extractall(EXTRACT_PATH)

# ======================================================
# 2‚ûî COLLECT VALID SAR IMAGES
# ======================================================
image_files = []
for root, _, files in os.walk(EXTRACT_PATH):
    if "__MACOSX" in root:
        continue
    for f in files:
        if f.startswith("._"):
            continue
        if f.lower().endswith((".tif", ".tiff", ".png", ".jpg", ".jpeg")):
            image_files.append(os.path.join(root, f))

#print("Valid SAR images:", len(image_files))

# ======================================================
# 3‚ûî LOAD ONE RANDOM SAR IMAGE
# ======================================================
while True:
    path = random.choice(image_files)
    try:
        img = Image.open(path).convert("L")
        break
    except UnidentifiedImageError:
        continue

print("Selected image:", os.path.basename(path))

img = img.resize((IMG_SIZE, IMG_SIZE))
img = np.array(img, dtype=np.float64)
img /= (np.max(img) + 1e-12)

# ======================================================
# 4‚ûî HD-QSAFE ENCODING
# ======================================================
def hd_qsafe_encode(image, feature_dim=256):
    flat = image.flatten()
    blocks = np.array_split(flat, feature_dim)
    features = np.array([np.mean(b) for b in blocks])

    amplitudes = np.sqrt(features + 1e-12)
    amplitudes /= np.linalg.norm(amplitudes)

    probs = amplitudes**2

    q_img = np.interp(
        np.linspace(0, len(probs), image.size, endpoint=False),
        np.arange(len(probs)),
        probs
    ).reshape(image.shape)

    return q_img

quantum_img = hd_qsafe_encode(img, FEATURE_DIM)
quantum_img /= np.max(quantum_img)

# ======================================================
# 5‚ûî QUANTUM IMAGE OPERATIONS (HD-QSAFE-AWARE)
# ======================================================

# ‚ÜîÔ∏è Quantum Rotation (90¬∞)
quantum_rotated = np.rot90(quantum_img)

# üîÉ Quantum Flipping
quantum_flip_h = np.fliplr(quantum_img)
quantum_flip_v = np.flipud(quantum_img)

# üí§ Quantum Filtering (Probability-domain smoothing)
quantum_filtered = cv2.GaussianBlur(quantum_img, (5,5), 0)
quantum_filtered /= np.max(quantum_filtered)

# ======================================================
# 6‚ûî VISUALIZATION
# ======================================================
plt.figure(figsize=(12,8))

plt.subplot(2,3,1)
plt.title("Original SAR Image")
plt.imshow(img, cmap="gray")
plt.axis("off")
plt.savefig("sar_original_image.png")

plt.subplot(2,3,2)
plt.title("HD-QSAFE Quantum Image")
plt.imshow(quantum_img, cmap="hot")
plt.axis("off")
plt.savefig("sar_hd_qsafe_quantum_image.png")

plt.subplot(2,3,3)
plt.title("Quantum Rotation (90¬∞)")
plt.imshow(quantum_rotated, cmap="hot")
plt.axis("off")
plt.savefig("sar_quantum_rotated.png")

plt.subplot(2,3,4)
plt.title("Quantum Flip (Horizontal)")
plt.imshow(quantum_flip_h, cmap="hot")
plt.axis("off")
plt.savefig("sar_quantum_flip_horizontal.png")

plt.subplot(2,3,5)
plt.title("Quantum Flip (Vertical)")
plt.imshow(quantum_flip_v, cmap="hot")
plt.axis("off")
plt.savefig("sar_quantum_flip_vertical.png")

plt.subplot(2,3,6)
plt.title("Quantum Filtering")
plt.imshow(quantum_filtered, cmap="hot")
plt.axis("off")
plt.savefig("sar_quantum_filtered.png")

plt.tight_layout()
plt.show()